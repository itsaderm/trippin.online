# trippin.online

## Overview

This project consists of two components: a Python script (`scraper.py`) and a PHP file (`index.php`). The purpose of this project is to create a fun and relaxing experience for users, especially those looking to chill out and enjoy random images while tripping on psychedelics. 
The Python script scrapes images from Reddit, converts them to WebP format, and saves them locally. The PHP file then serves these images in a randomized manner, refreshing every 3 minutes by default.

> **Note:** This project was entirely generated by ChatGPT and is intended as a fun project for relaxation and enjoyment.

## `scraper.py`

### Purpose
`scraper.py` is a script designed to scrape image posts from specified subreddits on Reddit, convert them to WebP format, and save them locally.

### Features
- **Reddit API Integration:** Uses the PRAW library to interact with Reddit and fetch posts from subreddits.
- **Rate Limiting:** Implements rate limiting to avoid hitting Reddit's API too frequently.
- **Image Processing:** Converts images to WebP format for efficient storage and web usage.
- **Size Limiting:** Ensures that images exceeding a certain size are not processed.
- **State Management:** Keeps track of processed submissions to avoid re-downloading the same images.
- **Error Handling:** Includes error handling to manage issues with image downloading and saving.

### Key Functions
- `rate_limit()`: Manages API rate limits by pausing the script when the query limit is reached.
- `save_image_as_webp(image_url, file_name, subreddit_name)`: Downloads an image from a URL, converts it to WebP format, and saves it to the local filesystem.
- `scan_reddit(subreddit_name)`: Searches a specified subreddit for image posts, processes them, and saves valid images.

### Configuration
- **Reddit API Credentials:** Replace the placeholders for `client_id` and `client_secret` with your actual Reddit API credentials.
- **Subreddits:** The list of subreddits to scan is defined in the `subreddit_list` variable. Modify this list based on your needs.

### Dependencies
- `praw`: Python Reddit API Wrapper
- `requests`: HTTP library for making requests
- `PIL` (Pillow): Python Imaging Library for image processing
- `json`, `os`, `random`, `time`, `warnings`: Standard Python libraries

## `index.php`

### Purpose
`index.php` serves a random image from the local `images` directory. It refreshes the displayed image every 3 minutes, unless specified with the `/?t=` variable in the url bar.

### Features
- **Image Display:** Randomly selects an image from the `images` folder and serves it to the user.
- **Session Management:** Uses PHP sessions to keep track of which images have been displayed to avoid repetition.
- **Refresh Interval:** Allows the user to specify the refresh interval in minutes via a URL parameter (`t`).

### Key Components
- **Session Handling:** Manages image indexing and tracking through PHP sessions to ensure images are not repeated until all have been shown.
- **Image MIME Type Detection:** Sets the correct MIME type for the served image based on its extension.
- **Cache Control:** Disables caching to ensure that the image displayed is always the latest.

### Configuration
- **Image Folder:** The path to the folder containing images is set in the `$folder` variable. Ensure this path matches where your images are stored.
- **Refresh Interval:** Specify the refresh interval in minutes by passing a `t` parameter in the URL (e.g., `domain.com/?t=10` for a 10-minute interval).

### Dependencies
- **PHP:** Web server with PHP support

## Usage Instructions

1. **Setup `scraper.py`:**
   - Install required Python libraries using pip:
   - 
     ```bash
     pip install praw requests pillow
     ```
   - Update the Reddit API credentials and the subreddit list as needed.
   - Run the script to start scraping and saving images:
   - 
     ```bash
     python scraper.py
     ```

2. **Setup `index.php`:**
   - Place `index.php` on a PHP-enabled web server.
   - Ensure the `images` directory is in the same directory as `index.php` and contains the images saved by `scraper.py`.

3. **Access the Web Interface:**
   - Open a web browser and navigate to the URL where `index.php` is hosted. Use the `t` parameter to set the refresh interval if desired.

## Notes
- **Image Storage:** Ensure that the `images` folder is writable by the web server and contains the images downloaded by `scraper.py`.
- **Error Handling:** Regularly check both the Python and PHP error logs for issues and address them as necessary.

Feel free to modify the script and PHP file according to your specific requirements. Enjoy the relaxing experience!

---

*This project was a fun exercise generated by ChatGPT. It aims to provide a calming and enjoyable experience for users. Use responsibly and have fun!*

## Contact

If you have any questions or need further assistance, you can reach out to me on Discord: **aderm**.
